{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFDDKkJfkQjy"
      },
      "outputs": [],
      "source": [
        "! pip install -q langchain transformers sentence_transformers llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex,GPTSimpleVectorIndex, PromptHelper\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import LLMPredictor, ServiceContext\n",
        "import torch\n",
        "from langchain.llms.base import LLM\n",
        "from transformers import pipeline\n",
        "from llama_index import Document\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger().setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "aGCX8IBekbNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customLLM(LLM):\n",
        "    model_name = \"google/flan-t5-large\"\n",
        "    pipeline = pipeline(\"text2text-generation\", model=model_name, device=0, model_kwargs={\"torch_dtype\":torch.bfloat16})\n",
        "    initial_prompt = 'You are a Q&A bot, a highly intelligent question answering bot based on the information provided by the user. If the answer cannot be found in the information, write \"I could not find an answer.\"'\n",
        "\n",
        "    def _call(self, prompt, stop=None):\n",
        "        text = f\"{self.initial_prompt}\\n\\n{prompt} {stop}\" if stop is not None else f\"{self.initial_prompt}\\n\\n{prompt}\"\n",
        "        return self.pipeline(text, max_length=9999)[0][\"generated_text\"]\n",
        " \n",
        "    def _identifying_params(self):\n",
        "        return {\"name_of_model\": self.model_name}\n",
        "\n",
        "    def _llm_type(self):\n",
        "        return \"custom\"\n",
        "\n",
        "\n",
        "llm_predictor = LLMPredictor(llm=customLLM())\n"
      ],
      "metadata": {
        "id": "nVcWX65LkfG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfemb = HuggingFaceEmbeddings()\n",
        "embed_model = LangchainEmbedding(hfemb)"
      ],
      "metadata": {
        "id": "Noq5r9_jkiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save your remember to questions in this text_list DB"
      ],
      "metadata": {
        "id": "D_nF0zLBfBc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = [\"remember i have kept my keys in the bedroom drawer\", \"I need to go to shopping on saturday\"]\n",
        "\n",
        "documents = [Document(t) for t in text_list]"
      ],
      "metadata": {
        "id": "DFM8PBkZpsaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\n",
        "index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "B2oE7bPfpyif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query( \"Where did I keep my keys?\") \n",
        "response.response"
      ],
      "metadata": {
        "id": "LQKYPoKVfRS7",
        "outputId": "fae1d4bf-91b1-4793-b685-1831d90657ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in the bedroom drawer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query( \"when is my next shopping date?\") \n",
        "response.response"
      ],
      "metadata": {
        "id": "m4S97OWafUMm",
        "outputId": "5bb99c84-f2e1-481f-cbf4-18e4fc8bf917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Saturday'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query( \"how much money do i have?\") \n",
        "response.response"
      ],
      "metadata": {
        "id": "jZzgg5rUfaJF",
        "outputId": "4dbdb674-e4d1-4b36-8521-74c6389ab0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I could not find an answer.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}